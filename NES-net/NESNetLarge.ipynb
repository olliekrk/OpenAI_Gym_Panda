{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "from sklearn import metrics\n",
    "import math\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "from tensorflow.keras.applications.nasnet import NASNetLarge, preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pixels = 331\n",
    "\n",
    "# Input pixel dimensions.  All training and test examples will be resized to (pixel, pixel, 3)\n",
    "conv_base = NASNetLarge(weights='imagenet', include_top=False, input_shape=(pixels,pixels,3))\n",
    "\n",
    "conv_base.trainable = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6693 images belonging to 40 classes.\n",
      "Found 2839 images belonging to 40 classes.\n"
     ]
    }
   ],
   "source": [
    "sf40_dir = \"./Sanford40\"\n",
    "BATCH_SIZE = 20\n",
    "\n",
    "sf40_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=10,\n",
    "    zoom_range= [0.9,1.1],\n",
    "    horizontal_flip=True,\n",
    "    validation_split=0.3) # set validation split\n",
    "\n",
    "train_generator = sf40_datagen.flow_from_directory(\n",
    "    sf40_dir,\n",
    "    batch_size=BATCH_SIZE, \n",
    "    target_size=(pixels, pixels),\n",
    "    class_mode = 'categorical',\n",
    "    subset='training') # set as training data\n",
    "\n",
    "validation_generator = sf40_datagen.flow_from_directory(\n",
    "    sf40_dir, \n",
    "    batch_size=BATCH_SIZE, \n",
    "    target_size=(pixels, pixels),\n",
    "    class_mode = 'categorical',\n",
    "    subset='validation') # set as validation data\n",
    "\n",
    "y_true = validation_generator.classes\n",
    "\n",
    "train_m = len(train_generator.classes)\n",
    "valid_m = len(validation_generator.classes)\n",
    "\n",
    "mapping = dict()\n",
    "for activity, idx in train_generator.class_indices.items():\n",
    "    mapping[idx] = activity\n",
    "\n",
    "train_steps = math.ceil(train_m/BATCH_SIZE)\n",
    "valid_steps = math.ceil(valid_m/BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "NASNet (Functional)          (None, 11, 11, 4032)      84916818  \n",
      "_________________________________________________________________\n",
      "ClassConv (Conv2D)           (None, 11, 11, 1024)      37159936  \n",
      "_________________________________________________________________\n",
      "GAP (GlobalAveragePooling2D) (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "class (Dense)                (None, 40)                41000     \n",
      "=================================================================\n",
      "Total params: 122,117,754\n",
      "Trainable params: 37,200,936\n",
      "Non-trainable params: 84,916,818\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(conv_base)\n",
    "model.add(layers.Conv2D(1024, (3, 3), padding=\"same\", strides=(1, 1), activation=\"relu\", name=\"ClassConv\"))\n",
    "model.add(layers.GlobalAveragePooling2D(name=\"GAP\"))\n",
    "model.add(layers.Dense(40, activation=\"softmax\", name=\"class\"))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "\n",
    "filepath = \"models/class_only/checkpoints/epoch_{epoch:02d}-{val_loss:.2f}.h5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=False, mode='min')\n",
    "\n",
    "#callback = tf.keras.callbacks.EarlyStopping(monitor='classification_loss', patience=5)\n",
    "\n",
    "logdir = \"models/class_only/logs\"\n",
    "\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizers.Adam(lr=1e-4), metrics = ['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "335/335 [==============================] - 2571s 8s/step - loss: 0.8977 - acc: 0.7478 - val_loss: 0.7019 - val_acc: 0.7996\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.70186, saving model to models/class_only/checkpoints\\epoch_01-0.70.h5\n",
      "Epoch 2/20\n",
      "335/335 [==============================] - 2557s 8s/step - loss: 0.4201 - acc: 0.8714 - val_loss: 0.6203 - val_acc: 0.8232\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.70186 to 0.62030, saving model to models/class_only/checkpoints\\epoch_02-0.62.h5\n",
      "Epoch 3/20\n",
      "335/335 [==============================] - 2562s 8s/step - loss: 0.2579 - acc: 0.9163 - val_loss: 0.6358 - val_acc: 0.8193\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.62030\n",
      "Epoch 4/20\n",
      "335/335 [==============================] - 2554s 8s/step - loss: 0.1771 - acc: 0.9411 - val_loss: 0.6895 - val_acc: 0.8218\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.62030\n",
      "Epoch 5/20\n",
      "335/335 [==============================] - 2521s 8s/step - loss: 0.1262 - acc: 0.9588 - val_loss: 0.7028 - val_acc: 0.8211\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.62030\n",
      "Epoch 6/20\n",
      "335/335 [==============================] - 2494s 7s/step - loss: 0.0998 - acc: 0.9631 - val_loss: 0.7481 - val_acc: 0.8207\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.62030\n",
      "Epoch 7/20\n",
      "335/335 [==============================] - 2479s 7s/step - loss: 0.0804 - acc: 0.9728 - val_loss: 0.7913 - val_acc: 0.8084\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.62030\n",
      "Epoch 8/20\n",
      "335/335 [==============================] - 2478s 7s/step - loss: 0.0770 - acc: 0.9753 - val_loss: 0.7909 - val_acc: 0.8112\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.62030\n",
      "Epoch 9/20\n",
      "335/335 [==============================] - 2586s 8s/step - loss: 0.0723 - acc: 0.9780 - val_loss: 0.8669 - val_acc: 0.8228\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.62030\n",
      "Epoch 10/20\n",
      "182/335 [===============>..............] - ETA: 14:13 - loss: 0.0730 - acc: 0.9766"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "history = model.fit_generator(train_generator, steps_per_epoch=train_steps, epochs=epochs, validation_data=validation_generator, validation_steps=valid_steps, callbacks=[tensorboard_callback, checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'dev'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'dev'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " BATCH_SIZE = 12\n",
    "\n",
    "pixels = 224\n",
    "train_datagen = ImageDataGenerator(rescale=1./255, horizontal_flip=True, rotation_range=10, zoom_range= [0.9,1.1])\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "valid_generator = multiple_outputs(test_datagen, \n",
    "                                   image_dir=sf40_dir, \n",
    "                                   batch_size=BATCH_SIZE, \n",
    "                                   image_size=pixels)\n",
    "\n",
    "valid_temp = test_datagen.flow_from_directory(sf40_dir, batch_size=BATCH_SIZE, target_size=(pixels,pixels), class_mode = 'categorical', shuffle=False)\n",
    "y_true = valid_temp.classes\n",
    "\n",
    "valid_m = len(valid_temp.classes)\n",
    "\n",
    "mapping = dict()\n",
    "for activity, idx in valid_temp.class_indices.items():\n",
    "    mapping[idx] = activity\n",
    "\n",
    "\n",
    "valid_steps = math.ceil(valid_m/BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 12\n",
    "\n",
    "valid_generator = test_datagen.flow_from_directory(sf40_dir, batch_size=BATCH_SIZE, target_size=(pixels,pixels), class_mode = 'categorical', shuffle=False)\n",
    "\n",
    "y_true = valid_generator.classes\n",
    "\n",
    "valid_m = len(valid_generator.classes)\n",
    "\n",
    "mapping = dict()\n",
    "for activity, idx in train_generator.class_indices.items():\n",
    "    mapping[idx] = activity\n",
    "\n",
    "valid_steps = math.ceil(valid_m/BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict_generator(valid_generator, valid_steps)\n",
    "predictions = predictions.argmax(axis=1)\n",
    "matrix = metrics.confusion_matrix(y_true, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df_cm = pd.DataFrame(matrix, index = [mapping[i] for i in range(40)], columns = [mapping[i] for i in range(40)])\n",
    "plt.figure(figsize = (40, 40))\n",
    "sn.heatmap(df_cm, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
